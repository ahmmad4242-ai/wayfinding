"""
Agent-Based Simulation - Ù…Ø­Ø§ÙƒØ§Ø© Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
Based on: Huang et al. (2017), HÃ¶lscher et al. (2006)
"""
import numpy as np
import networkx as nx
from typing import Dict, List, Any, Tuple, Optional
from loguru import logger
from dataclasses import dataclass
from enum import Enum


class AgentType(Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"""
    FAMILIAR = "familiar"  # Ù…Ø¹ØªØ§Ø¯
    FIRST_TIME = "first_time"  # Ø²Ø§Ø¦Ø± Ù„Ø£ÙˆÙ„ Ù…Ø±Ø©
    ELDERLY = "elderly"  # ÙƒØ¨Ø§Ø± Ø§Ù„Ø³Ù†
    MOBILITY_IMPAIRED = "mobility_impaired"  # Ù…Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø­Ø±ÙƒØ©


@dataclass
class Agent:
    """ÙˆÙƒÙŠÙ„ ÙŠÙ…Ø«Ù„ Ù…Ø³ØªØ®Ø¯Ù…"""
    id: str
    agent_type: AgentType
    current_position: Tuple[float, float]
    target_position: Tuple[float, float]
    path: List[Tuple[float, float]] = None
    errors: int = 0
    hesitations: int = 0
    sign_usages: int = 0
    time_elapsed: float = 0
    distance_traveled: float = 0
    success: bool = False


class AgentSimulator:
    """Ù…Ø­Ø§ÙƒÙŠ Ø³Ù„ÙˆÙƒ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡"""
    
    def __init__(self):
        self.graph = None
        self.signage_locations = []
        self.landmarks = []
        self.agents = []
    
    async def simulate(
        self,
        graph: nx.Graph,
        scenarios: List[Dict[str, Any]],
        n_agents_per_scenario: int = 100,
        signage_locations: List = None,
        landmarks: List = None
    ) -> Dict[str, Any]:
        """
        ØªØ´ØºÙŠÙ„ Ù…Ø­Ø§ÙƒØ§Ø© Agent-Based
        
        Args:
            graph: Ø´Ø¨ÙƒØ© Ø§Ù„Ø­Ø±ÙƒØ©
            scenarios: Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª (Ù…Ø¯Ø®Ù„ â†’ ÙˆØ¬Ù‡Ø©)
            n_agents_per_scenario: Ø¹Ø¯Ø¯ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ Ù„ÙƒÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ
            signage_locations: Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
            landmarks: Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ø§Ù„Ø¨Ø§Ø±Ø²Ø©
        
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
        """
        try:
            logger.info(f"ğŸ¤– Starting agent simulation with {len(scenarios)} scenarios...")
            
            self.graph = graph
            self.signage_locations = signage_locations or []
            self.landmarks = landmarks or []
            
            all_results = []
            
            for scenario in scenarios:
                origin = scenario.get("origin")
                destination = scenario.get("destination")
                scenario_name = scenario.get("name", f"{origin}->{destination}")
                
                logger.info(f"Simulating scenario: {scenario_name}")
                
                # ØªØ´ØºÙŠÙ„ Ø¹Ø¯Ø© ÙˆÙƒÙ„Ø§Ø¡ Ù„Ù†ÙØ³ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ
                scenario_results = await self._run_scenario(
                    origin,
                    destination,
                    n_agents_per_scenario
                )
                
                all_results.append({
                    "scenario": scenario_name,
                    "origin": origin,
                    "destination": destination,
                    **scenario_results
                })
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            overall_stats = await self._calculate_overall_stats(all_results)
            
            result = {
                "scenarios": all_results,
                "overall": overall_stats,
                "recommendations": await self._generate_recommendations(all_results)
            }
            
            logger.info("âœ… Agent simulation completed")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Error in agent simulation: {str(e)}")
            raise
    
    async def _run_scenario(
        self,
        origin: str,
        destination: str,
        n_agents: int
    ) -> Dict[str, Any]:
        """
        ØªØ´ØºÙŠÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ÙˆØ§Ø­Ø¯ Ù…Ø¹ Ø¹Ø¯Ø© ÙˆÙƒÙ„Ø§Ø¡
        """
        agents = []
        
        # ØªÙˆØ²ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡
        agent_types_dist = [
            (AgentType.FIRST_TIME, 0.6),
            (AgentType.FAMILIAR, 0.2),
            (AgentType.ELDERLY, 0.15),
            (AgentType.MOBILITY_IMPAIRED, 0.05)
        ]
        
        for i in range(n_agents):
            # Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„ÙˆÙƒÙŠÙ„
            agent_type = np.random.choice(
                [at for at, _ in agent_types_dist],
                p=[prob for _, prob in agent_types_dist]
            )
            
            # Ø¥Ù†Ø´Ø§Ø¡ ÙˆÙƒÙŠÙ„
            agent = Agent(
                id=f"agent_{i}",
                agent_type=agent_type,
                current_position=self._get_node_position(origin),
                target_position=self._get_node_position(destination)
            )
            
            # ØªØ´ØºÙŠÙ„ Ø±Ø­Ù„Ø© Ø§Ù„ÙˆÙƒÙŠÙ„
            await self._simulate_agent_journey(agent, origin, destination)
            
            agents.append(agent)
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        return await self._aggregate_scenario_results(agents)
    
    def _get_node_position(self, node: str) -> Tuple[float, float]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙˆÙ‚Ø¹ Ø¹Ù‚Ø¯Ø©"""
        if node in self.graph.nodes:
            return self.graph.nodes[node].get('pos', (0, 0))
        return (0, 0)
    
    async def _simulate_agent_journey(
        self,
        agent: Agent,
        origin: str,
        destination: str
    ):
        """
        Ù…Ø­Ø§ÙƒØ§Ø© Ø±Ø­Ù„Ø© ÙˆÙƒÙŠÙ„ Ù…Ù† Ø§Ù„Ø£ØµÙ„ Ù„Ù„ÙˆØ¬Ù‡Ø©
        """
        try:
            # Ø­Ø³Ø§Ø¨ Ø£Ù‚ØµØ± Ù…Ø³Ø§Ø±
            if origin not in self.graph or destination not in self.graph:
                agent.success = False
                return
            
            shortest_path = nx.shortest_path(
                self.graph, origin, destination, weight='weight'
            )
            
            # ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø³Ø§Ø± Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ÙˆÙƒÙŠÙ„
            actual_path = await self._apply_agent_strategy(
                agent,
                shortest_path,
                destination
            )
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            agent.path = actual_path
            agent.distance_traveled = await self._calculate_path_length(actual_path)
            agent.time_elapsed = await self._estimate_travel_time(agent, actual_path)
            agent.success = (actual_path[-1] == destination if actual_path else False)
            
        except Exception as e:
            logger.warning(f"Agent {agent.id} failed: {e}")
            agent.success = False
    
    async def _apply_agent_strategy(
        self,
        agent: Agent,
        optimal_path: List[str],
        destination: str
    ) -> List[str]:
        """
        ØªØ·Ø¨ÙŠÙ‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø³Ø§Ø± Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ÙˆÙƒÙŠÙ„
        """
        actual_path = [optimal_path[0]]
        current = optimal_path[0]
        
        for i, next_node in enumerate(optimal_path[1:], 1):
            # Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚Ø±Ø§Ø±
            error_prob = self._get_error_probability(agent, current)
            
            if np.random.random() < error_prob:
                # Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±
                agent.errors += 1
                
                # Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ø¬ÙŠØ±Ø§Ù†
                neighbors = list(self.graph.neighbors(current))
                if neighbors:
                    wrong_choice = np.random.choice(neighbors)
                    actual_path.append(wrong_choice)
                    current = wrong_choice
                    
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØµØ­ÙŠØ­
                    if wrong_choice != next_node:
                        agent.hesitations += 1
                        try:
                            correction_path = nx.shortest_path(
                                self.graph, wrong_choice, destination, weight='weight'
                            )
                            actual_path.extend(correction_path[1:])
                            return actual_path
                        except:
                            return actual_path
            else:
                # Ø§Ø®ØªÙŠØ§Ø± ØµØ­ÙŠØ­
                # ÙØ­Øµ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
                if self._signage_visible_at(current, next_node):
                    agent.sign_usages += 1
                
                actual_path.append(next_node)
                current = next_node
        
        return actual_path
    
    def _get_error_probability(self, agent: Agent, node: str) -> float:
        """
        Ø­Ø³Ø§Ø¨ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ø¹Ù‚Ø¯Ø©
        """
        base_prob = {
            AgentType.FAMILIAR: 0.05,
            AgentType.FIRST_TIME: 0.25,
            AgentType.ELDERLY: 0.35,
            AgentType.MOBILITY_IMPAIRED: 0.30
        }
        
        prob = base_prob.get(agent.agent_type, 0.20)
        
        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ Ø¹Ù†Ø¯ Ø¹Ù‚Ø¯ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¯Ø±Ø¬Ø© (ØªÙØ±Ø¹ ÙƒØ¨ÙŠØ±)
        degree = self.graph.degree(node)
        if degree >= 4:
            prob *= 1.5
        elif degree >= 3:
            prob *= 1.2
        
        # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø¥Ø´Ø§Ø±Ø©
        if self._has_signage_at(node):
            prob *= 0.5
        
        # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø¹Ù„Ù… Ø¨Ø§Ø±Ø²
        if self._has_landmark_at(node):
            prob *= 0.6
        
        return min(prob, 0.9)  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 90%
    
    def _signage_visible_at(self, current: str, next_node: str) -> bool:
        """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù…Ø±Ø¦ÙŠØ©"""
        # ØªØ¨Ø³ÙŠØ·: Ù†ÙØªØ±Ø¶ ÙˆØ¬ÙˆØ¯ Ø¥Ø´Ø§Ø±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
        return current in self.signage_locations or next_node in self.signage_locations
    
    def _has_signage_at(self, node: str) -> bool:
        """ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ø¥Ø´Ø§Ø±Ø© Ø¹Ù†Ø¯ Ø¹Ù‚Ø¯Ø©"""
        return node in self.signage_locations
    
    def _has_landmark_at(self, node: str) -> bool:
        """ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ù…Ø¹Ù„Ù… Ø¹Ù†Ø¯ Ø¹Ù‚Ø¯Ø©"""
        return node in self.landmarks
    
    async def _calculate_path_length(self, path: List[str]) -> float:
        """Ø­Ø³Ø§Ø¨ Ø·ÙˆÙ„ Ø§Ù„Ù…Ø³Ø§Ø±"""
        if len(path) < 2:
            return 0
        
        total_length = 0
        for i in range(len(path) - 1):
            if path[i] in self.graph and path[i+1] in self.graph:
                if self.graph.has_edge(path[i], path[i+1]):
                    total_length += self.graph[path[i]][path[i+1]].get('weight', 1)
        
        return total_length
    
    async def _estimate_travel_time(
        self,
        agent: Agent,
        path: List[str]
    ) -> float:
        """
        ØªÙ‚Ø¯ÙŠØ± Ø²Ù…Ù† Ø§Ù„Ø³ÙØ± (Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ)
        """
        distance = await self._calculate_path_length(path)
        
        # Ø³Ø±Ø¹Ø© Ø§Ù„Ù…Ø´ÙŠ (Ù…/Ø«)
        walking_speed = {
            AgentType.FAMILIAR: 1.4,
            AgentType.FIRST_TIME: 1.0,
            AgentType.ELDERLY: 0.8,
            AgentType.MOBILITY_IMPAIRED: 0.6
        }
        
        speed = walking_speed.get(agent.agent_type, 1.0)
        
        # Ø§Ù„Ø²Ù…Ù† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        base_time = distance / speed
        
        # Ø¥Ø¶Ø§ÙØ© Ø²Ù…Ù† Ø§Ù„ØªÙˆÙ‚Ù ÙˆØ§Ù„ØªØ±Ø¯Ø¯
        hesitation_time = agent.hesitations * 5  # 5 Ø«ÙˆØ§Ù†Ù Ù„ÙƒÙ„ ØªØ±Ø¯Ø¯
        error_time = agent.errors * 10  # 10 Ø«ÙˆØ§Ù†Ù Ù„ÙƒÙ„ Ø®Ø·Ø£
        
        total_time = base_time + hesitation_time + error_time
        
        return total_time
    
    async def _aggregate_scenario_results(
        self,
        agents: List[Agent]
    ) -> Dict[str, Any]:
        """
        ØªØ¬Ù…ÙŠØ¹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ
        """
        successful = [a for a in agents if a.success]
        
        if not agents:
            return {}
        
        return {
            "n_agents": len(agents),
            "success_rate": len(successful) / len(agents),
            "first_pass_success": sum(1 for a in agents if a.success and a.errors == 0) / len(agents),
            "mean_time": float(np.mean([a.time_elapsed for a in successful])) if successful else 0,
            "std_time": float(np.std([a.time_elapsed for a in successful])) if successful else 0,
            "mean_distance": float(np.mean([a.distance_traveled for a in successful])) if successful else 0,
            "mean_errors": float(np.mean([a.errors for a in agents])),
            "mean_hesitations": float(np.mean([a.hesitations for a in agents])),
            "mean_sign_usage": float(np.mean([a.sign_usages for a in agents])),
            "hesitation_rate": float(np.mean([
                a.hesitations / a.distance_traveled if a.distance_traveled > 0 else 0
                for a in agents
            ]))
        }
    
    async def _calculate_overall_stats(
        self,
        all_results: List[Dict]
    ) -> Dict[str, Any]:
        """
        Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        """
        all_success_rates = [r.get("success_rate", 0) for r in all_results]
        all_times = [r.get("mean_time", 0) for r in all_results]
        all_errors = [r.get("mean_errors", 0) for r in all_results]
        
        return {
            "overall_success_rate": float(np.mean(all_success_rates)),
            "overall_mean_time": float(np.mean(all_times)),
            "overall_mean_errors": float(np.mean(all_errors)),
            "best_scenario": max(all_results, key=lambda x: x.get("success_rate", 0)).get("scenario"),
            "worst_scenario": min(all_results, key=lambda x: x.get("success_rate", 0)).get("scenario")
        }
    
    async def _generate_recommendations(
        self,
        all_results: List[Dict]
    ) -> List[str]:
        """
        ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©
        """
        recommendations = []
        
        # Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø°Ø§Øª Ù…Ø¹Ø¯Ù„ Ù†Ø¬Ø§Ø­ Ù…Ù†Ø®ÙØ¶
        low_success = [r for r in all_results if r.get("success_rate", 1) < 0.7]
        if low_success:
            recommendations.append(
                f"ØªØ­Ø³ÙŠÙ† Ù…Ø³Ø§Ø±Ø§Øª: {', '.join([r['scenario'] for r in low_success[:3]])} "
                f"(Ù…Ø¹Ø¯Ù„ Ù†Ø¬Ø§Ø­ < 70%)"
            )
        
        # Ø²Ù…Ù† Ø³ÙØ± Ù…Ø±ØªÙØ¹
        high_time = [r for r in all_results if r.get("mean_time", 0) > 180]  # > 3 Ø¯Ù‚Ø§Ø¦Ù‚
        if high_time:
            recommendations.append(
                f"ØªÙ‚Ù„ÙŠÙ„ Ø²Ù…Ù† Ø§Ù„Ø³ÙØ± ÙÙŠ: {', '.join([r['scenario'] for r in high_time[:3]])}"
            )
        
        # Ø£Ø®Ø·Ø§Ø¡ Ù…ØªÙƒØ±Ø±Ø©
        high_errors = [r for r in all_results if r.get("mean_errors", 0) > 1.5]
        if high_errors:
            recommendations.append(
                f"Ø¥Ø¶Ø§ÙØ© Ø¥Ø´Ø§Ø±Ø§Øª Ø¹Ù†Ø¯: {', '.join([r['scenario'] for r in high_errors[:3]])}"
            )
        
        if not recommendations:
            recommendations.append("Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù… - Ù„Ø§ ØªÙˆØµÙŠØ§Øª Ø­Ø±Ø¬Ø©")
        
        return recommendations
